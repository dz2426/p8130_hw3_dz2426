---
title: "hw3_dz2426"
author: "Duzhi Zhao"
date: "10/7/2019"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(viridis)
library(leaflet)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE,
  fig.width = 12, 
  fig.height = 10,
  out.width = "100%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1
# Description of "Instacart" dataset
```{r include = FALSE}
# Import data set "instacart"
library(p8105.datasets)
data("instacart")

skimr::skim(instacart) # Summary statistics
```
Comments:

This limited "Instacart" dataset contains 1,384,617 observations of 131,209 unique users, and 15 columns of variables. Some key variables are "aisle"  "department", "product_name", "reordered", and "order_dow".

"aisle" contains 134 groups, such as yogurt, fresh vegetables, and fresh fruits. "product_name" includes 39123 products, such as Bulgarian Yogurt, Organic Celery Hearts, and Bag of Organic Bananas. "department" includes 21 departments, such as dairy eggs, produce, canned goods. "reordered" shows whether the item has been ordered by this user in the past. "order_dow" indicates the day of the week on which the order is placed

# Section 1.1
```{r echo = FALSE}
instacart_data_q1 = instacart %>% 
  janitor::clean_names() %>% 
  count(aisle) %>% #count the number of items ordered from each aisle
  arrange(desc(n)) #sort in descending order
```
Comments:

There are `r range(pull(instacart, aisle_id))[2]` aisles in total and the aisle "fresh vegetables" has the most items ordered from.

# Section 1.2
```{r echo = FALSE}
items_order_df = instacart %>% 
  janitor::clean_names() %>% 
  count(aisle) %>% #count the number of items in each aisle
  filter(n > 10000) %>% #filter items ordered > 10000
  rename(count = n)

items_order_plot = 
  items_order_df %>% 
  mutate(aisle = as.factor(aisle)) %>% #factor aisle into different levels
  ggplot(aes(x = aisle, y = count)) +
  geom_col() + #show bar graph
  coord_flip() + #xy axis flip 
  labs(
    title = "Figure 1: Number of items ordered in each aisle (>10000)"
  ) +
  ylim(0, 170000) 
items_order_plot
```

# Section 1.3
```{r echo = FALSE}
pop_items_df = 
  instacart %>% 
  select(aisle_id, aisle, product_name) %>% #select the data we want
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% #filter out these three aisle groups
  count(aisle, product_name) %>% #count the number of each product under each aisle 
  group_by(aisle) %>% #order by group
  top_n(n = 3) %>% #select the top 3 popular products
  mutate(
    rank = dense_rank(desc(n)) #rank each product by each group
  ) %>% 
  arrange(aisle, rank) %>% 
  rename("ordered_times" = 3) %>% 
  select(-rank)

```

Table 1: The three most popular products in each of the aisles
```{r echo = FALSE}
knitr::kable(pop_items_df)
```

```{r echo = FALSE}
pink_coffee_df = instacart %>% 
  select(order_hour_of_day, order_dow, product_name) %>% #select the data we are interested in
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% #filter out these two products
  group_by(order_dow, product_name) %>% 
  arrange(order_dow, order_hour_of_day) %>% 
  mutate(
    mean_order_hour = round(mean(order_hour_of_day) , digits = 0)
  )

pink_coffee_table = tibble(
  mean_order_hour = c(pull(pink_coffee_df, mean_order_hour)),
  order_day = c(pull(pink_coffee_df, order_dow)),
  product_name = c(pull(pink_coffee_df, product_name)) #create variables we want
) %>% 
  distinct() %>% #remove dupplicated rows
  mutate(
    order_day = recode(order_day, 
                       "0" = "Mon",
                       "1" = "Tue",
                       "2" = "Wed",
                       "3" = "Thu",
                       "4" = "Fri",
                       "5" = "Sat",
                       "6" = "Sun")
  ) %>% #transform integer to name of each day
  pivot_wider(
    names_from = product_name,
    values_from = mean_order_hour
  ) %>% #2x7 table
  janitor::clean_names() %>% 
  rename(pink_lady_apples_order_hr = 2) %>% 
  rename(coffee_ice_cream_order_hr = 3) #clean up names

```

# Section 1.4
Table 2: Mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
```{r echo = FALSE}
knitr::kable(pink_coffee_table)
```

## Problem 2
```{r echo = FALSE}
#Import and clean data set
data("brfss_smart2010")

brfss2010 = brfss_smart2010 %>% 
  janitor::clean_names() %>% 
  rename(state = locationabbr,  #rename variables
         county = locationdesc,
         health_class = class,
         response_id = respid) %>% 
  filter(topic == "Overall Health", 
         response %in% c("Poor", "Good", "Fair", "Very good", "Excellent")
  ) %>% #filter the topic and filter out the response
  mutate(
    response = ordered(response, levels = c("Poor", "Fair", "Good", "Very good", "Excellent"))
  ) %>% 
  arrange(response) #arrange from poor to excellent in descending order
```

# Section 2.1
```{r echo = FALSE}
locations2002_df = 
  brfss2010 %>% 
  filter(year == 2002) %>% 
  count(state) %>% 
  mutate(
    n_of_locations = n/4 #After observing dataset, I notice there are 4 responses for each location. Thus, the number of each distinct locations equals the total number of observations divded by 4
  ) %>% 
  filter(n_of_locations > 6) 

locations2010_df = 
  brfss2010 %>% 
  filter(year == 2010) %>% 
  count(state) %>% 
  mutate(
    n_of_locations = n/4 
  ) %>% 
  filter(n_of_locations > 6) 
```
Comments:

In 2002, `r c(pull(locations2002_df, state))` were observed at 7 or more locations. In 2010, `r c(pull(locations2010_df, state))` were observed at 7 or more locations.

# Section 2.2
```{r echo = FALSE}
# Construct dataset limited to "Excellent" response
excellent_resp = 
  brfss2010 %>% 
  group_by(year, state) %>% 
  select(year, state, response, data_value) %>% 
  filter(response == "Excellent")  %>% 
  drop_na() %>% #remove NA 
  mutate(
    mean_data_val = round(mean(data_value), digits = 2) #mean of data_value grouped by year and state
  ) %>% 
  select(-data_value,
         -response) %>% 
  distinct() #remove duplicated rows
```

```{r echo = FALSE}
excellent_resp %>% 
  ggplot(aes(x = year, y = mean_data_val, color = state)) +
  geom_line() +
  xlab("Year") +
  ylab("Average value") +
  ggtitle("Figure 2a: Average value within each state from 2002 to 2010")
```

```{r echo = FALSE}
excellent_resp %>% 
  ggplot(aes(x = year, y = mean_data_val, group = state)) +
  geom_point(size = 1) +
  geom_line() +
  facet_wrap(~state, nrow = 4) + 
  xlab("Year") +
  ylab("Average value") +
  ggtitle("Figure 2b: Figure 2a shown with separate plots based on states") +
  theme(axis.text.x = element_text(size = 5),
        axis.text.y = element_text(size = 8),
        axis.title = element_text(size = 15),
        strip.text = element_text(size = 10),
        title = element_text(size = 13),
        panel.spacing.x = unit(1, "lines")
  )
```

# Section 2.3 
```{r echo = FALSE}
NY_response = 
  brfss2010 %>% 
  select(year, state, county, data_value, response) %>% 
  filter(year == 2006 | year == 2010,
         state %in% c("NY")) #Select data

NY_response %>% 
  ggplot(aes(x = response, y = data_value)) + 
  geom_boxplot() +
  facet_grid(~year) + 
  ylab("data value") +
  ggtitle("Figure 3: Distribution of data value for responses (“Poor” to “Excellent”) in NY") + 
  theme(title = element_text(size = 13),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 14),
        axis.text.x = element_text(size = 8),
        axis.text.y = element_text(size = 8)
        )

```

## Problem 3
# Section 3.1
```{r echo = FALSE}
# Import and clean dataset without changing "activity_n" columns
accel_data_act = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day = ordered(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")), #change day into factor and reorder in a classical Mon-Sun way
    if_weekday = ifelse(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") == TRUE, "weekday", "weekend") #determine if it is a weekday
  ) %>% 
  subset(select = c(1, 2, 3, 1444, 4:1443)) #reorder columns

```

```{r echo = FALSE}
# Tidy dataset by creating "minute" variable
accel_data_min = read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    day = ordered(day, levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")), #change day into factor and reorder in a classical Mon-Sun way
    if_weekday = ifelse(
      day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday") == TRUE, "weekday", "weekend") #determine if it is a weekday
  ) %>% 
  arrange(week, day) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute", 
    names_prefix = "activity_",
    values_to = "activity_counts"
  ) %>% 
  mutate(
    minute = as.numeric(minute) #change from character to numeric
  )
```
Comments: 

The tidied "accel_data" dataset contains `r dim(accel_data_min)[1]` observations and `r dim(accel_data_min)[2]` variables. This continuous 5-week accelerometer data was collected for monitoring the physicial activity of a 63 year-old male with BMI 25 who was diagnosed with congestive heart failure (CHF). 

Numeric variable "week" includes number 1-5, indicating the number of weeks this experiment was at. Factor variable "day" refers to the day the accelerometer was monitoring on over 5 weeks. Character variable "if_weekday" shows if the day is a weekday or weeekend. Numeric variable "minute" lists out each minute within each day over 5 weeks. Numeric variable "activity_counts" shows the physicial activity of this 63 year-old male on every minute over 5 weeks.

# Section 3.2
```{r echo = FALSE}
accel_total = accel_data_act %>% 
  mutate(
    total_activity = select(., activity_1:activity_1440) %>% 
      rowSums(na.rm = TRUE) %>% #select activity columns and sum all columns on each row
      round(digits = 0) #round to the nearest integer
  ) %>% 
  select(week, day, total_activity) %>%  #remove all minutely activity columns
  arrange(day) %>% 
  pivot_wider(
    names_from = day,
    values_from = total_activity
  )
```

Table 3: Total activity measured in minutes of a 63 year-old male with BMI 25 on each day over 5 weeks
```{r echo = FALSE}
knitr::kable(accel_total)
```

Comments:

Based on the table shown above, we could observe that the physical activity tends to increase during weekdays over the 5 weeks, and tends to decrease during weekends over the 5 weeks. This may indicate that this 63 year-old male was getting less active during weekends, while more active during weekdays.


# Section 3.3
```{r echo = FALSE}
accel_time_course = accel_data_act %>% 
  mutate( #Sum up the activity count for each hour
    "1" = select(., activity_1:activity_60) %>% 
      rowSums(na.rm = TRUE),
    "2" = select(., activity_61:activity_120) %>% 
      rowSums(na.rm = TRUE),
    "3" = select(., activity_121:activity_180) %>% 
      rowSums(na.rm = TRUE),
    "4" = select(., activity_181:activity_240) %>% 
      rowSums(na.rm = TRUE),
    "5" = select(., activity_241:activity_300) %>% 
      rowSums(na.rm = TRUE),
    "6" = select(., activity_301:activity_360) %>% 
      rowSums(na.rm = TRUE),
    "7" = select(., activity_361:activity_420) %>% 
      rowSums(na.rm = TRUE),
    "8" = select(., activity_421:activity_480) %>% 
      rowSums(na.rm = TRUE),
    "9" = select(., activity_481:activity_540) %>% 
      rowSums(na.rm = TRUE),
    "10" = select(., activity_541:activity_600) %>% 
      rowSums(na.rm = TRUE),
    "11" = select(., activity_601:activity_660) %>% 
      rowSums(na.rm = TRUE),
    "12" = select(., activity_661:activity_720) %>% 
      rowSums(na.rm = TRUE),
    "13" = select(., activity_721:activity_780) %>% 
      rowSums(na.rm = TRUE),
    "14" = select(., activity_781:activity_840) %>% 
      rowSums(na.rm = TRUE),
    "15" = select(., activity_841:activity_900) %>% 
      rowSums(na.rm = TRUE),
    "16" = select(., activity_901:activity_960) %>% 
      rowSums(na.rm = TRUE),
    "17" = select(., activity_961:activity_1020) %>% 
      rowSums(na.rm = TRUE),
    "18" = select(., activity_1021:activity_1080) %>% 
      rowSums(na.rm = TRUE),
    "19" = select(., activity_1081:activity_1140) %>% 
      rowSums(na.rm = TRUE),
    "20" = select(., activity_1141:activity_1200) %>% 
      rowSums(na.rm = TRUE),
    "21" = select(., activity_1201:activity_1260) %>% 
      rowSums(na.rm = TRUE),
    "22" = select(., activity_1261:activity_1320) %>% 
      rowSums(na.rm = TRUE),
    "23" = select(., activity_1321:activity_1380) %>% 
      rowSums(na.rm = TRUE),
    "24" = select(., activity_1381:activity_1440) %>% 
      rowSums(na.rm = TRUE)
  ) %>% 
  subset(select = c(1, 3, 1445:1468)) %>% #select needed variables
  arrange(week,day) %>% 
  pivot_longer(
    3:26,
    names_to = "time_of_day_hr",
    values_to = "activity_count"
  ) %>% 
  mutate(
    time_of_day_hr = as.numeric(time_of_day_hr) #change to numeric for later plotting 
  )
```

```{r echo = FALSE}
# Split time-course data into 5 individual weeks
accel_week1 = accel_time_course[1:168,]
accel_week2 = accel_time_course[169:336,]
accel_week3 = accel_time_course[337:504,]
accel_week4 = accel_time_course[505:672,]
accel_week5 = accel_time_course[673:840,]

```

```{r echo = FALSE}
# Add up all lines corresponding to each day of the week
ggplot(accel_time_course, aes(x = time_of_day_hr, y = activity_count)) +
  geom_line(data = accel_week1, aes(colour = day)) +
  geom_line(data = accel_week2, aes(colour = day)) +
  geom_line(data = accel_week3, aes(colour = day)) +
  geom_line(data = accel_week4, aes(colour = day)) +
  geom_line(data = accel_week5, aes(colour = day)) +
  xlab("Time of day (hour)") + 
  ylab("Activity counts") +
  ggtitle("Figure 4a: Physical activity of a 63 year-old male with BMI 25 over 5 weeks") +
  theme(title = element_text(size = 13),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 12),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        legend.key.size = unit(1, "cm")
        )

```

```{r echo = FALSE}
week_label = c(`1` = "week 1", 
              `2` = "week 2", 
              `3` = "week 3", 
              `4` = "week 4", 
              `5` = "week 5")

accel_time_course %>% 
  ggplot(aes(x = time_of_day_hr, y = activity_count)) +
  geom_line(aes(color = day)) +
  facet_grid(~week, 
             labeller = as_labeller(week_label)) +
  xlab("Time of day (hour)") +
  ylab("Activity counts") +
  ggtitle("Figure 4b: Figure 4a displayed with each week individually") +
  theme(panel.spacing.x = unit(1, "lines"),
        title = element_text(size = 13),
        axis.title = element_text(size = 14),
        strip.text = element_text(size = 14),
        axis.text.x = element_text(size = 10),
        axis.text.y = element_text(size = 10),
        legend.key.size = unit(1, "cm")
  )
```

